name: Scheduler - Full Football Scraper

on:
  schedule:
    - cron: '0 2 * * 0,1,3,4,5,6'            # Every day except Tuesdays at 3/4 AM (Spanish time)
    - cron: '0 2 * 1,2,8,9 2'                # Every Tuesday at 3/4 AM (Spanish time) in Jan, Feb, Aug, Sep
    - cron: '0 2 * 3,4,5,6,7,10,11,12 2'     # Every Tuesday at 3/4 AM (Spanish time) except Jan, Feb, Aug, Sep
    - cron: '0 7 * 4,5,6,7,8,9,10 *'         # This runs at 9 AM every day (Spanish summer time)
    - cron: '0 8 * 1,2,3,11,12 *'            # This runs at 9 AM every day (Spanish winter time)
    - cron: '30 22 * 4,5,6,7,8,9,10 *'       # This runs at 00:30 every day (Spanish summer time)
    - cron: '30 23 * 1,2,3,11,12 *'          # This runs at 00:30 every day (Spanish winter time)
#    - cron: '0 2 * * *'                     # This runs at 3/4 AM every day (Spanish time)
  workflow_dispatch: # Allows manual triggering

jobs:
  scrape_biwenger:
    runs-on: ubuntu-latest
    timeout-minutes: 15  # Set the job timeout to 15 minutes
    if: (github.event_name == 'workflow_dispatch') || ((github.event.schedule != '0 7 * 4,5,6,7,8,9,10 *') && (github.event.schedule != '0 8 * 1,2,3,11,12 *'))
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.13'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run Biwenger Scraper
        run: python -u ./scraping_tasks/scrape_biwenger.py

      - name: Upload Biwenger DATA files as artifact
        uses: actions/upload-artifact@v4
        with:
          name: biwenger-data
          path: |
            csv_files/*biwenger*.csv
            json_files/*biwenger*.json

  scrape_laligafantasy:
    runs-on: ubuntu-latest
    timeout-minutes: 10  # Set the job timeout to 10 minutes
    if: (github.event_name == 'workflow_dispatch') || ((github.event.schedule != '0 7 * 4,5,6,7,8,9,10 *') && (github.event.schedule != '0 8 * 1,2,3,11,12 *'))
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.13'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run LaLigaFantasy Scraper
        run: python -u ./scraping_tasks/scrape_laligafantasy.py

      - name: Upload LaLigaFantasy DATA files as artifact
        uses: actions/upload-artifact@v4
        with:
          name: laligafantasy-data
          path: |
            csv_files/*laligafantasy*.csv
            json_files/*laligafantasy*.json

  scrape_elo_ratings:
    runs-on: ubuntu-latest
    timeout-minutes: 60  # Set the job timeout to 60 minutes
    if: (github.event_name == 'workflow_dispatch') || ((github.event.schedule != '0 7 * 4,5,6,7,8,9,10 *') && (github.event.schedule != '0 8 * 1,2,3,11,12 *'))
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.13'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run Elo Ratings Scraper
        run: python -u ./scraping_tasks/scrape_elo_ratings.py

      - name: Upload Elo Ratings DATA files as artifact
        uses: actions/upload-artifact@v4
        with:
          name: elo-ratings-data
          path: |
            csv_files/*elo*ratings*.csv
            json_files/*elo*ratings*.json

  scrape_futbolfantasy:
    runs-on: ubuntu-latest
    timeout-minutes: 60  # Set the job timeout to 60 minutes
#    if: (github.event_name == 'workflow_dispatch') || ((github.event.schedule != '0 7 * 4,5,6,7,8,9,10 *') && (github.event.schedule != '0 8 * 1,2,3,11,12 *'))
    strategy:
      fail-fast: false
      max-parallel: 13
      matrix:
        league:
          - laliga
#          - premier
          - seriea
#          - bundesliga
#          - ligueone
          - segunda
          - champions
#          - europaleague
#          - conference
      #   - mundialito
      #   - mundial
      #   - eurocopa
      #   - copaamerica
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.13'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

#      - name: Run FutbolFantasy Scraper
#        run: python -u ./scraping_tasks/scrape_futbolfantasy.py

      - name: Run FutbolFantasy Scraper (${{ matrix.league }})
        run: |
          python -u ./scraping_tasks/futbolfantasy_scrapers/scrape_futbolfantasy_${{ matrix.league }}.py

#      - name: Upload FutbolFantasy DATA files as artifact
      - name: Upload FutbolFantasy DATA files as artifact (${{ matrix.league }})
        uses: actions/upload-artifact@v4
        with:
#          name: futbolfantasy-data
          name: futbolfantasy-data-${{ matrix.league }}
          path: |
            csv_files/*futbolfantasy_${{ matrix.league }}*.csv
            json_files/*futbolfantasy_${{ matrix.league }}*.json

  scrape_analiticafantasy:
    runs-on: ubuntu-latest
    timeout-minutes: 60  # Set the job timeout to 60 minutes
#    if: (github.event_name == 'workflow_dispatch') || (github.event.schedule == '0 7 * 4,5,6,7,8,9,10 *') || (github.event.schedule == '0 8 * 1,2,3,11,12 *')
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.13'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run AnaliticaFantasy Scraper
        run: python -u ./scraping_tasks/scrape_analiticafantasy.py

      - name: Upload AnaliticaFantasy DATA files as artifact
        uses: actions/upload-artifact@v4
        with:
          name: analiticafantasy-data
          path: |
            csv_files/*analiticafantasy*.csv
            json_files/*analiticafantasy*.json

  scrape_jornadaperfecta:
    runs-on: ubuntu-latest
    timeout-minutes: 60  # Set the job timeout to 60 minutes
#    if: (github.event_name == 'workflow_dispatch') || ((github.event.schedule != '0 7 * 4,5,6,7,8,9,10 *') && (github.event.schedule != '0 8 * 1,2,3,11,12 *'))
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.13'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run JornadaPerfecta Scraper
        run: python -u ./scraping_tasks/scrape_jornadaperfecta.py

      - name: Upload JornadaPerfecta DATA files as artifact
        uses: actions/upload-artifact@v4
        with:
          name: jornadaperfecta-data
          path: |
            csv_files/*jornadaperfecta*.csv
            json_files/*jornadaperfecta*.json

  scrape_pundit:
    runs-on: ubuntu-latest
    timeout-minutes: 60  # Set the job timeout to 60 minutes
#    if: (github.event_name == 'workflow_dispatch') || ((github.event.schedule != '0 7 * 4,5,6,7,8,9,10 *') && (github.event.schedule != '0 8 * 1,2,3,11,12 *'))
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.13'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run Pundit Scraper
        run: python -u ./scraping_tasks/scrape_pundit.py

      - name: Upload Pundit DATA files as artifact
        uses: actions/upload-artifact@v4
        with:
          name: pundit-data
          path: |
            csv_files/*pundit*.csv
            json_files/*pundit*.json

  scrape_scout:
    runs-on: ubuntu-latest
    timeout-minutes: 60  # Set the job timeout to 60 minutes
#    if: (github.event_name == 'workflow_dispatch') || ((github.event.schedule != '0 7 * 4,5,6,7,8,9,10 *') && (github.event.schedule != '0 8 * 1,2,3,11,12 *'))
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.13'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run Scout Scraper
        run: python -u ./scraping_tasks/scrape_scout.py

      - name: Upload Scout DATA files as artifact
        uses: actions/upload-artifact@v4
        with:
          name: scout-data
          path: |
            csv_files/*scout*.csv
            json_files/*scout*.json

  scrape_rotowire:
    runs-on: ubuntu-latest
    timeout-minutes: 60  # Set the job timeout to 60 minutes
#    if: (github.event_name == 'workflow_dispatch') || ((github.event.schedule != '0 7 * 4,5,6,7,8,9,10 *') && (github.event.schedule != '0 8 * 1,2,3,11,12 *'))
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.13'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run RotoWire Scraper
        run: python -u ./scraping_tasks/scrape_rotowire.py

      - name: Upload RotoWire DATA files as artifact
        uses: actions/upload-artifact@v4
        with:
          name: rotowire-data
          path: |
            csv_files/*rotowire*.csv
            json_files/*rotowire*.json

  scrape_sportsgambler:
    runs-on: ubuntu-latest
    timeout-minutes: 60  # Set the job timeout to 60 minutes
#    if: (github.event_name == 'workflow_dispatch') || ((github.event.schedule != '0 7 * 4,5,6,7,8,9,10 *') && (github.event.schedule != '0 8 * 1,2,3,11,12 *'))
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.13'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run SportsGambler Scraper
        run: python -u ./scraping_tasks/scrape_sportsgambler.py

      - name: Upload SportsGambler DATA files as artifact
        uses: actions/upload-artifact@v4
        with:
          name: sportsgambler-data
          path: |
            csv_files/*sportsgambler*.csv
            json_files/*sportsgambler*.json

  scrape_futmondo:
    runs-on: ubuntu-latest
    timeout-minutes: 30  # Set the job timeout to 30 minutes
    if: (github.event_name == 'workflow_dispatch') || (github.event.schedule == '0 2 * 1,2,8,9 2')
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.13'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run Futmondo Scraper
        run: python -u ./scraping_tasks/scrape_futmondo.py

      - name: Upload Futmondo DATA files as artifact
        uses: actions/upload-artifact@v4
        with:
          name: futmondo-data
          path: |
            csv_files/*futmondo*.csv
            json_files/*futmondo*.json

  scrape_transfermarket_penalty_takers:
    runs-on: ubuntu-latest
#    timeout-minutes: 180  # Set the job timeout to 180 minutes
    timeout-minutes: 120  # Set the job timeout to 120 minutes
    if: (github.event_name == 'workflow_dispatch') || ((github.event.schedule != '0 7 * 4,5,6,7,8,9,10 *') && (github.event.schedule != '0 8 * 1,2,3,11,12 *'))
    strategy:
      fail-fast: false
      max-parallel: 13
      matrix:
        league:
          - laliga
          - premier
          - seriea
          - bundesliga
          - ligueone
          - segunda
          - champions
          - europaleague
          - conference
      #   - mundialito
      #   - mundial
      #   - eurocopa
      #   - copaamerica
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.13'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

#      - name: Run TransferMarket Penalty Takers Scraper
#        run: python -u ./scraping_tasks/scrape_transfermarket_penalty_takers_single.py

      - name: Run TransferMarket Penalty Takers Scraper (${{ matrix.league }})
        run: |
          python -u ./scraping_tasks/transfermarket_penalty_takers_scrapers/scrape_transfermarket_penalty_takers_${{ matrix.league }}.py

#      - name: Upload TransferMarket Penalty Takers DATA files as artifact
      - name: Upload TransferMarket Penalty Takers DATA files as artifact (${{ matrix.league }})
        uses: actions/upload-artifact@v4
        with:
#          name: transfermarket-penalty-takers-data
          name: transfermarket-penalty-takers-data-${{ matrix.league }}
          path: |
            csv_files/*transfermarket_${{ matrix.league }}*penalt*taker*.csv
            json_files/*transfermarket_${{ matrix.league }}*penalt*taker*.json

  scrape_transfermarket_penalty_savers:
    runs-on: ubuntu-latest
    timeout-minutes: 180  # Set the job timeout to 180 minutes
    if: (github.event_name == 'workflow_dispatch') || ((github.event.schedule != '0 7 * 4,5,6,7,8,9,10 *') && (github.event.schedule != '0 8 * 1,2,3,11,12 *'))
    strategy:
      fail-fast: false
      max-parallel: 13
      matrix:
        league:
          - laliga
          - premier
          - seriea
          - bundesliga
          - ligueone
          - segunda
          - champions
          - europaleague
          - conference
      #   - mundialito
      #   - mundial
      #   - eurocopa
      #   - copaamerica
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.13'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

#      - name: Run TransferMarket Penalty Savers Scraper
#        run: python -u ./scraping_tasks/scrape_transfermarket_penalty_savers_single.py

      - name: Run TransferMarket Penalty Savers Scraper (${{ matrix.league }})
        run: |
          python -u ./scraping_tasks/transfermarket_penalty_savers_scrapers/scrape_transfermarket_penalty_savers_${{ matrix.league }}.py

#      - name: Upload TransferMarket Penalty Savers DATA files as artifact
      - name: Upload TransferMarket Penalty Savers DATA files as artifact (${{ matrix.league }})
        uses: actions/upload-artifact@v4
        with:
#          name: transfermarket-penalty-savers-data
          name: transfermarket-penalty-savers-data-${{ matrix.league }}
          path: |
            csv_files/*transfermarket_${{ matrix.league }}*penalt*saver*.csv
            json_files/*transfermarket_${{ matrix.league }}*penalt*saver*.json

  scrape_transfermarket_teamhistory:
    runs-on: ubuntu-latest
    timeout-minutes: 180  # Set the job timeout to 180 minutes
#    if: (github.event_name == 'workflow_dispatch') || (github.event_name == 'schedule' && github.event.schedule_weekday == '2' && (github.event.schedule_month == '8' || github.event.schedule_month == '9' || github.event.schedule_month == '1' || github.event.schedule_month == '2'))
    if: (github.event_name == 'workflow_dispatch') || (github.event.schedule == '0 2 * 1,2,8,9 2')
    strategy:
      fail-fast: false
      max-parallel: 13
      matrix:
        league:
          - laliga
          - premier
          - seriea
          - bundesliga
          - ligueone
          - segunda
          - champions
          - europaleague
          - conference
      #   - mundialito
      #   - mundial
      #   - eurocopa
      #   - copaamerica
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.13'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

#      - name: Run TransferMarket Team History Scraper
##        run: python -u ./scraping_tasks/scrape_transfermarket_teamhistory.py
#        run: python -u ./scraping_tasks/scrape_transfermarket_teamhistory_single.py

      - name: Run TransferMarket Team History Scraper (${{ matrix.league }})
        run: |
          python -u ./scraping_tasks/transfermarket_teamhistory_scrapers/scrape_transfermarket_teamhistory_${{ matrix.league }}.py

#      - name: Upload TransferMarket Team History DATA files as artifact
      - name: Upload TransferMarket Team History DATA files as artifact (${{ matrix.league }})
        uses: actions/upload-artifact@v4
        with:
#          name: transfermarket-teamhistory-data
          name: transfermarket-teamhistory-data-${{ matrix.league }}
          path: |
            csv_files/*transfermarket_${{ matrix.league }}*history*.csv
            json_files/*transfermarket_${{ matrix.league }}*history*.json


  scrape_sofascore:
    runs-on: ubuntu-latest
#    runs-on: ubuntu-22.04
    timeout-minutes: 60  # Set the job timeout to 60 minutes
#    if: (github.event_name == 'workflow_dispatch') || (github.event_name == 'schedule' && github.event.schedule_weekday == '2')
    if: (github.event_name == 'workflow_dispatch') || (github.event.schedule == '0 2 * 1,2,8,9 2' || github.event.schedule == '0 2 * 3,4,5,6,7,10,11,12 2' || github.event.schedule == '0 2 * * 0,1,3,4,5,6')
    strategy:
      fail-fast: false
      max-parallel: 13
      matrix:
        league:
          - laliga
          - premier
          - seriea
          - bundesliga
          - ligueone
          - segunda
          - champions
          - europaleague
          - conference
      #   - mundialito
      #   - mundial
      #   - eurocopa
      #   - copaamerica
    steps:
      - name: Enable Debug Logging
        run: |
          echo "ACTIONS_RUNNER_DEBUG=true" >> $GITHUB_ENV
          echo "ACTIONS_STEP_DEBUG=true" >> $GITHUB_ENV

      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.13'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
#
#      - name: Run SofaScore Scraper
#        run: python -u ./scraping_tasks/scrape_sofascore.py

      - name: Run SofaScore Scraper (${{ matrix.league }})
        run: |
          python -u ./scraping_tasks/sofascore_scrapers/scrape_sofascore_${{ matrix.league }}.py
#
#      - name: Upload SofaScore DATA files as artifact
#        uses: actions/upload-artifact@v4
#        with:
#          name: sofascore-data
#          path: |
#            csv_files/*sofascore*.csv
#            json_files/*sofascore*.json

      - name: Upload SofaScore DATA files as artifact (${{ matrix.league }})
        uses: actions/upload-artifact@v4
        with:
          name: sofascore-data-${{ matrix.league }}
          path: |
            csv_files/*sofascore_${{ matrix.league }}*.csv
            json_files/*sofascore_${{ matrix.league }}*.json

  commit-and-push:
    needs: [scrape_biwenger, scrape_laligafantasy, scrape_elo_ratings, scrape_futbolfantasy, scrape_analiticafantasy, scrape_jornadaperfecta, scrape_pundit, scrape_scout, scrape_rotowire, scrape_sportsgambler, scrape_futmondo, scrape_transfermarket_penalty_takers, scrape_transfermarket_penalty_savers, scrape_transfermarket_teamhistory, scrape_sofascore]
    if: ${{ always() && (
          (needs.scrape_biwenger.result == 'success' || needs.scrape_biwenger.result == 'skipped' || needs.scrape_biwenger.result == 'cancelled' || needs.scrape_biwenger.result == 'failure') &&
          (needs.scrape_laligafantasy.result == 'success' || needs.scrape_laligafantasy.result == 'skipped' || needs.scrape_laligafantasy.result == 'cancelled' || needs.scrape_laligafantasy.result == 'failure') &&
          (needs.scrape_elo_ratings.result == 'success' || needs.scrape_elo_ratings.result == 'skipped' || needs.scrape_elo_ratings.result == 'cancelled' || needs.scrape_elo_ratings.result == 'failure') &&
          (needs.scrape_futbolfantasy.result == 'success' || needs.scrape_futbolfantasy.result == 'skipped' || needs.scrape_futbolfantasy.result == 'cancelled' || needs.scrape_futbolfantasy.result == 'failure') &&
          (needs.scrape_analiticafantasy.result == 'success' || needs.scrape_analiticafantasy.result == 'skipped' || needs.scrape_analiticafantasy.result == 'cancelled' || needs.scrape_analiticafantasy.result == 'failure') &&
          (needs.scrape_jornadaperfecta.result == 'success' || needs.scrape_jornadaperfecta.result == 'skipped' || needs.scrape_jornadaperfecta.result == 'cancelled' || needs.scrape_jornadaperfecta.result == 'failure') &&
          (needs.scrape_pundit.result == 'success' || needs.scrape_pundit.result == 'skipped' || needs.scrape_pundit.result == 'cancelled' || needs.scrape_pundit.result == 'failure') &&
          (needs.scrape_scout.result == 'success' || needs.scrape_scout.result == 'skipped' || needs.scrape_scout.result == 'cancelled' || needs.scrape_scout.result == 'failure') &&
          (needs.scrape_rotowire.result == 'success' || needs.scrape_rotowire.result == 'skipped' || needs.scrape_rotowire.result == 'cancelled' || needs.scrape_rotowire.result == 'failure') &&
          (needs.scrape_sportsgambler.result == 'success' || needs.scrape_sportsgambler.result == 'skipped' || needs.scrape_sportsgambler.result == 'cancelled' || needs.scrape_sportsgambler.result == 'failure') &&
          (needs.scrape_futmondo.result == 'success' || needs.scrape_futmondo.result == 'skipped' || needs.scrape_futmondo.result == 'cancelled' || needs.scrape_futmondo.result == 'failure') &&
          (needs.scrape_transfermarket_penalty_takers.result == 'success' || needs.scrape_transfermarket_penalty_takers.result == 'skipped' || needs.scrape_transfermarket_penalty_takers.result == 'cancelled' || needs.scrape_transfermarket_penalty_takers.result == 'failure') &&
          (needs.scrape_transfermarket_penalty_savers.result == 'success' || needs.scrape_transfermarket_penalty_savers.result == 'skipped' || needs.scrape_transfermarket_penalty_savers.result == 'cancelled' || needs.scrape_transfermarket_penalty_savers.result == 'failure') &&
          (needs.scrape_transfermarket_teamhistory.result == 'success' || needs.scrape_transfermarket_teamhistory.result == 'skipped' || needs.scrape_transfermarket_teamhistory.result == 'cancelled' || needs.scrape_transfermarket_teamhistory.result == 'failure') &&
          (needs.scrape_sofascore.result == 'success' || needs.scrape_sofascore.result == 'skipped' || needs.scrape_sofascore.result == 'cancelled' || needs.scrape_sofascore.result == 'failure')
        )}}
    runs-on: ubuntu-latest
    timeout-minutes: 30  # Set the job timeout to 30 minutes
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Download Biwenger DATA artifact
        if: needs.scrape_biwenger.result == 'success'
        uses: actions/download-artifact@v4
        with:
          name: biwenger-data
          -path: data_files/biwenger/

      - name: Move Biwenger DATA files to root csv_files and json_files directories
        if: needs.scrape_biwenger.result == 'success'
        run: |
          mv -f data_files/biwenger/*.csv csv_files/ 2>/dev/null || true
          mv -f data_files/biwenger/*.json json_files/ 2>/dev/null || true
          rm -rf data_files/biwenger

      - name: Download LaLigaFantasy DATA artifact
        if: needs.scrape_laligafantasy.result == 'success'
        uses: actions/download-artifact@v4
        with:
          name: laligafantasy-data
          -path: data_files/laligafantasy/

      - name: Move LaLigaFantasy DATA files to root csv_files and json_files directories
        if: needs.scrape_laligafantasy.result == 'success'
        run: |
          mv -f data_files/laligafantasy/*.csv csv_files/ 2>/dev/null || true
          mv -f data_files/laligafantasy/*.json json_files/ 2>/dev/null || true
          rm -rf data_files/laligafantasy

      - name: Download Elo Ratings DATA artifact
        if: needs.scrape_elo_ratings.result == 'success'
        uses: actions/download-artifact@v4
        with:
          name: elo-ratings-data
          -path: data_files/elo_ratings/

      - name: Move Elo Ratings DATA files to root csv_files and json_files directories
        if: needs.scrape_elo_ratings.result == 'success'
        run: |
          mv -f data_files/elo_ratings/*.csv csv_files/ 2>/dev/null || true
          mv -f data_files/elo_ratings/*.json json_files/ 2>/dev/null || true
          rm -rf data_files/elo_ratings

      - name: Download FutbolFantasy DATA artifact
        if: needs.scrape_futbolfantasy.result == 'success'
        uses: actions/download-artifact@v4
        with:
#          name: futbolfantasy-data
          pattern: futbolfantasy-data-*
          merge-multiple: true
          -path: data_files/futbolfantasy/

      - name: Move FutbolFantasy DATA files to root csv_files and json_files directories
        if: needs.scrape_futbolfantasy.result == 'success'
        run: |
          mv -f data_files/futbolfantasy/*.csv csv_files/ 2>/dev/null || true
          mv -f data_files/futbolfantasy/*.json json_files/ 2>/dev/null || true
          rm -rf data_files/futbolfantasy

      - name: Download AnaliticaFantasy DATA artifact
        if: needs.scrape_analiticafantasy.result == 'success'
        uses: actions/download-artifact@v4
        with:
          name: analiticafantasy-data
          -path: data_files/analiticafantasy/

      - name: Move AnaliticaFantasy DATA files to root csv_files and json_files directories
        if: needs.scrape_analiticafantasy.result == 'success'
        run: |
          mv -f data_files/analiticafantasy/*.csv csv_files/ 2>/dev/null || true
          mv -f data_files/analiticafantasy/*.json json_files/ 2>/dev/null || true
          rm -rf data_files/analiticafantasy

      - name: Download JornadaPerfecta DATA artifact
        if: needs.scrape_jornadaperfecta.result == 'success'
        uses: actions/download-artifact@v4
        with:
          name: jornadaperfecta-data
          -path: data_files/jornadaperfecta/

      - name: Move JornadaPerfecta DATA files to root csv_files and json_files directories
        if: needs.scrape_jornadaperfecta.result == 'success'
        run: |
          mv -f data_files/jornadaperfecta/*.csv csv_files/ 2>/dev/null || true
          mv -f data_files/jornadaperfecta/*.json json_files/ 2>/dev/null || true
          rm -rf data_files/jornadaperfecta

      - name: Download Pundit DATA artifact
        if: needs.scrape_pundit.result == 'success'
        uses: actions/download-artifact@v4
        with:
          name: pundit-data
          -path: data_files/pundit/

      - name: Move Pundit DATA files to root csv_files and json_files directories
        if: needs.scrape_pundit.result == 'success'
        run: |
          mv -f data_files/pundit/*.csv csv_files/ 2>/dev/null || true
          mv -f data_files/pundit/*.json json_files/ 2>/dev/null || true
          rm -rf data_files/pundit

      - name: Download Scout DATA artifact
        if: needs.scrape_scout.result == 'success'
        uses: actions/download-artifact@v4
        with:
          name: scout-data
          -path: data_files/scout/

      - name: Move Scout DATA files to root csv_files and json_files directories
        if: needs.scrape_scout.result == 'success'
        run: |
          mv -f data_files/scout/*.csv csv_files/ 2>/dev/null || true
          mv -f data_files/scout/*.json json_files/ 2>/dev/null || true
          rm -rf data_files/scout

      - name: Download RotoWire DATA artifact
        if: needs.scrape_rotowire.result == 'success'
        uses: actions/download-artifact@v4
        with:
          name: rotowire-data
          -path: data_files/rotowire/

      - name: Move RotoWire DATA files to root csv_files and json_files directories
        if: needs.scrape_rotowire.result == 'success'
        run: |
          mv -f data_files/rotowire/*.csv csv_files/ 2>/dev/null || true
          mv -f data_files/rotowire/*.json json_files/ 2>/dev/null || true
          rm -rf data_files/rotowire

      - name: Download SportsGambler DATA artifact
        if: needs.scrape_sportsgambler.result == 'success'
        uses: actions/download-artifact@v4
        with:
          name: sportsgambler-data
          -path: data_files/sportsgambler/

      - name: Move SportsGambler DATA files to root csv_files and json_files directories
        if: needs.scrape_sportsgambler.result == 'success'
        run: |
          mv -f data_files/sportsgambler/*.csv csv_files/ 2>/dev/null || true
          mv -f data_files/sportsgambler/*.json json_files/ 2>/dev/null || true
          rm -rf data_files/sportsgambler

      - name: Download Futmondo DATA artifact
        if: needs.scrape_futmondo.result == 'success'
        uses: actions/download-artifact@v4
        with:
          name: futmondo-data
          -path: data_files/futmondo/

      - name: Move Futmondo DATA files to root csv_files and json_files directories
        if: needs.scrape_futmondo.result == 'success'
        run: |
          mv -f data_files/futmondo/*.csv csv_files/ 2>/dev/null || true
          mv -f data_files/futmondo/*.json json_files/ 2>/dev/null || true
          rm -rf data_files/futmondo

      - name: Download TransferMarket Penalty Takers DATA artifact
        if: needs.scrape_transfermarket_penalty_takers.result == 'success'
        uses: actions/download-artifact@v4
        with:
#          name: transfermarket-penalty-takers-data
          pattern: transfermarket-penalty-takers-data-*
          merge-multiple: true
          -path: data_files/transfermarket_penalty_takers/

      - name: Move TransferMarket Penalty Takers DATA files to root csv_files and json_files directories
        if: needs.scrape_transfermarket_penalty_takers.result == 'success'
        run: |
          mv -f data_files/transfermarket_penalty_takers/*.csv csv_files/ 2>/dev/null || true
          mv -f data_files/transfermarket_penalty_takers/*.json json_files/ 2>/dev/null || true
          rm -rf data_files/transfermarket_penalty_takers

      - name: Download TransferMarket Penalty Savers DATA artifact
        if: needs.scrape_transfermarket_penalty_savers.result == 'success'
        uses: actions/download-artifact@v4
        with:
#          name: transfermarket-penalty-savers-data
          pattern: transfermarket-penalty-savers-data-*
          merge-multiple: true
          -path: data_files/transfermarket_penalty_savers/

      - name: Move TransferMarket Penalty Savers DATA files to root csv_files and json_files directories
        if: needs.scrape_transfermarket_penalty_savers.result == 'success'
        run: |
          mv -f data_files/transfermarket_penalty_savers/*.csv csv_files/ 2>/dev/null || true
          mv -f data_files/transfermarket_penalty_savers/*.json json_files/ 2>/dev/null || true
          rm -rf data_files/transfermarket_penalty_savers

      - name: Download TransferMarket Team History DATA artifact
        if: needs.scrape_transfermarket_teamhistory.result == 'success'
        uses: actions/download-artifact@v4
        with:
#          name: transfermarket-teamhistory-data
          pattern: transfermarket-teamhistory-data-*
          merge-multiple: true
          -path: data_files/transfermarket_teamhistory/

      - name: Move TransferMarket Team History DATA files to root csv_files and json_files directories
        if: needs.scrape_transfermarket_teamhistory.result == 'success'
        run: |
          mv -f data_files/transfermarket_teamhistory/*.csv csv_files/ 2>/dev/null || true
          mv -f data_files/transfermarket_teamhistory/*.json json_files/ 2>/dev/null || true
          rm -rf data_files/transfermarket_teamhistory

      - name: Download SofaScore DATA artifact
        if: needs.scrape_sofascore.result == 'success'
        uses: actions/download-artifact@v4
        with:
#          name: sofascore-data
          pattern: sofascore-data-*
          merge-multiple: true
          -path: data_files/sofascore/

      - name: Move SofaScore DATA files to root csv_files and json_files directories
        if: needs.scrape_sofascore.result == 'success'
        run: |
          mv -f data_files/sofascore/*.csv csv_files/ 2>/dev/null || true
          mv -f data_files/sofascore/*.json json_files/ 2>/dev/null || true
          rm -rf data_files/sofascore

      - name: Configure git
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'

      - name: Update auto-update trigger in streamlit_app.py
        run: |
          TRIGGER_LINE="# Auto-update trigger: $(date)"
          if grep -q "^# Auto-update trigger:" streamlit_app.py; then
            sed -i "s/^# Auto-update trigger:.*/$TRIGGER_LINE/" streamlit_app.py
          else
            echo "$TRIGGER_LINE" >> streamlit_app.py
          fi

      - name: Commit changes
        run: |
          git add streamlit_app.py
          git add csv_files/*.csv
          git add json_files/*.json
          git commit -m "Automated commit by GitHub Action"

      - name: Push changes
        uses: ad-m/github-push-action@v0.6.0
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
